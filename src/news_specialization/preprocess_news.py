import json
import re
import unicodedata
import pandas as pd

class NewsPreprocessor:
    def __init__(self, filepath=None, data=None):
        """
        Khá»Ÿi táº¡o bá»™ tiá»n xá»­ lÃ½.
        :param filepath: ÄÆ°á»ng dáº«n tá»›i file JSON (náº¿u cÃ³).
        :param data: Dá»¯ liá»‡u dáº¡ng list hoáº·c dict (náº¿u khÃ´ng load tá»« file).
        """
        self.data = []
        if filepath:
            self.load_data(filepath)
        elif data:
            self.data = data

    def load_data(self, filepath):
        """Äá»c file JSON (xá»­ lÃ½ cáº¥u trÃºc lá»“ng nhau náº¿u cáº§n)."""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                
            # Kiá»ƒm tra cáº¥u trÃºc file (trÆ°á»ng há»£p file upload cÃ³ key 'fullContent')
            if isinstance(raw_data, dict) and 'fullContent' in raw_data:
                self.data = raw_data['fullContent']
            elif isinstance(raw_data, list):
                self.data = raw_data
            else:
                raise ValueError("Cáº¥u trÃºc JSON khÃ´ng Ä‘Æ°á»£c há»— trá»£.")
            
            print(f"âœ… ÄÃ£ load {len(self.data)} bÃ i bÃ¡o.")
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c file: {e}")

    def clean_text(self, text):
        """
        HÃ m lÃ m sáº¡ch vÄƒn báº£n chÃ­nh cho tiáº¿ng Viá»‡t.
        """
        if not isinstance(text, str) or not text:
            return ""

        # 1. Chuáº©n hÃ³a Unicode (chuyá»ƒn vá» dá»±ng sáºµn NFC - quan trá»ng cho tiáº¿ng Viá»‡t)
        text = unicodedata.normalize('NFC', text)

        # 2. Loáº¡i bá» URL
        text = re.sub(r'https?://\S+|www\.\S+', '', text)

        # 3. Loáº¡i bá» cÃ¡c cá»¥m tá»« thÆ°á»ng gáº·p trong bÃ¡o chÃ­ (Caption áº£nh, nguá»“n)
        # VÃ­ dá»¥: "áº¢nh: ...", "Nguá»“n: ...", "Theo ..." á»Ÿ Ä‘áº§u cÃ¢u hoáº·c cuá»‘i Ä‘oáº¡n
        text = re.sub(r'(áº¢nh|Nguá»“n|Theo)\s*[:].*?(\n|$)', ' ', text, flags=re.IGNORECASE)
        
        # 4. Loáº¡i bá» thÃ´ng tin ngÃ y thÃ¡ng rÃ¡c dáº¡ng "13/11/2025 11:21" náº±m lÆ¡ lá»­ng trong text
        text = re.sub(r'\d{1,2}/\d{1,2}/\d{4}\s+\d{1,2}:\d{1,2}', '', text)

        # 5. Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t khÃ´ng mong muá»‘n (giá»¯ láº¡i dáº¥u cÃ¢u cÆ¡ báº£n vÃ  tiáº¿ng Viá»‡t)
        # Pattern nÃ y giá»¯ láº¡i chá»¯ cÃ¡i, sá»‘, vÃ  cÃ¡c dáº¥u cÃ¢u phá»• biáº¿n
        text = re.sub(r'[^\w\s,.;:?!%\(\)\"\'-]', ' ', text)

        # 6. Xá»­ lÃ½ khoáº£ng tráº¯ng (newlines thÃ nh space, xÃ³a double space)
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    def filter_relevant_content(self, keyword="Credit Suisse"):
        """
        Lá»c cÃ¡c bÃ i viáº¿t chá»‰ liÃªn quan Ä‘áº¿n tá»« khÃ³a (náº¿u cáº§n thiáº¿t).
        Dá»¯ liá»‡u cá»§a báº¡n cÃ³ nhiá»u bÃ i khÃ´ng liÃªn quan (showbiz, tai náº¡n).
        """
        initial_count = len(self.data)
        # Lá»c náº¿u keyword xuáº¥t hiá»‡n trong title hoáº·c content
        self.data = [
            article for article in self.data 
            if keyword.lower() in str(article.get('title', '')).lower() 
            or keyword.lower() in str(article.get('content', '')).lower()
        ]
        print(f"ğŸ” ÄÃ£ lá»c bÃ i viáº¿t theo tá»« khÃ³a '{keyword}': {initial_count} -> {len(self.data)}")

    def remove_duplicates(self):
        """Loáº¡i bá» cÃ¡c bÃ i bÃ¡o trÃ¹ng láº·p dá»±a trÃªn Title."""
        df = pd.DataFrame(self.data)
        if df.empty:
            return
        
        initial_count = len(df)
        # XÃ³a trÃ¹ng láº·p dá»±a trÃªn tiÃªu Ä‘á» (title)
        df.drop_duplicates(subset=['title'], keep='first', inplace=True)
        
        self.data = df.to_dict('records')
        print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a {initial_count - len(df)} bÃ i viáº¿t trÃ¹ng láº·p.")

    def process(self, filter_keyword=None):
        """
        Cháº¡y toÃ n bá»™ quy trÃ¬nh tiá»n xá»­ lÃ½.
        """
        processed_data = []
        
        # BÆ°á»›c 1: Lá»c trÃ¹ng láº·p trÆ°á»›c khi xá»­ lÃ½ Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian
        self.remove_duplicates()

        # BÆ°á»›c 2: Lá»c ná»™i dung theo tá»« khÃ³a (TÃ¹y chá»n)
        if filter_keyword:
            self.filter_relevant_content(filter_keyword)

        # BÆ°á»›c 3: Clean text
        for article in self.data:
            clean_article = article.copy()
            
            # LÃ m sáº¡ch Title
            clean_article['clean_title'] = self.clean_text(article.get('title', ''))
            
            # LÃ m sáº¡ch Content
            clean_article['clean_content'] = self.clean_text(article.get('content', ''))
            
            # TÃ­nh Ä‘á»™ dÃ i word count (há»¯u Ã­ch Ä‘á»ƒ lá»c bÃ i quÃ¡ ngáº¯n)
            clean_article['word_count'] = len(clean_article['clean_content'].split())

            # Chá»‰ láº¥y bÃ i cÃ³ ná»™i dung Ä‘Ã¡ng ká»ƒ (>20 tá»«)
            if clean_article['word_count'] > 20:
                processed_data.append(clean_article)

        self.data = processed_data
        print("âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t.")
        return self.data

    def save_to_json(self, output_path):
        """LÆ°u káº¿t quáº£ ra file JSON."""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u file táº¡i: {output_path}")

# --- VÃ­ dá»¥ cÃ¡ch sá»­ dá»¥ng ---
if __name__ == "__main__":
    # ÄÆ°á»ng dáº«n file cá»§a báº¡n
    input_file = 'news_credit_suisse.json'
    output_file = 'cleaned_news_data.json'

    # Khá»Ÿi táº¡o
    processor = NewsPreprocessor(filepath=input_file)

    # Cháº¡y xá»­ lÃ½ (CÃ³ thá»ƒ truyá»n tá»« khÃ³a 'Credit Suisse' Ä‘á»ƒ lá»c bá» tin rÃ¡c nhÆ° Showbiz/Tai náº¡n)
    # Náº¿u muá»‘n giá»¯ táº¥t cáº£, Ä‘á»ƒ filter_keyword=None
    cleaned_data = processor.process(filter_keyword="Credit Suisse")

    # Xem thá»­ 1 bÃ i
    if cleaned_data:
        print("\n--- VÃ­ dá»¥ bÃ i viáº¿t sau khi clean ---")
        print("Title:", cleaned_data[0]['clean_title'])
        print("Content Snippet:", cleaned_data[0]['clean_content'][:200], "...")

    # LÆ°u file
    processor.save_to_json(output_file)