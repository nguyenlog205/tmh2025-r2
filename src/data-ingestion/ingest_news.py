# https://news.google.com/home?hl=vi&gl=VN&ceid=VN:vi

import time
from selenium import webdriver
from selenium.common.exceptions import WebDriverException
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

from bs4 import BeautifulSoup
import pandas as pd

# ===========================================================================================================================
# Hyperparameter Configuration 
# ===========================================================================================================================
MAIN_URL = 'https://news.google.com/home?hl=vi&gl=VN&ceid=VN:vi'

# ===========================================================================================================================
# Driver Loading Function 
# ===========================================================================================================================

def load_driver() -> webdriver.Chrome | None:
    """
    Khá»Ÿi táº¡o Chrome WebDriver á»Ÿ cháº¿ Ä‘á»™ cÆ¡ báº£n nháº¥t Ä‘á»ƒ cháº¡y local.
    """
    options = webdriver.ChromeOptions()
    try:
        print("ğŸš€ Äang khá»Ÿi táº¡o Chrome WebDriver (cháº¿ Ä‘á»™ cÆ¡ báº£n)...")
        driver = webdriver.Chrome(options=options)
        print("âœ… WebDriver Ä‘Ã£ sáºµn sÃ ng.")
        return driver
        
    except WebDriverException as e:
        print(f"âŒ Lá»—i: KhÃ´ng thá»ƒ khá»Ÿi táº¡o WebDriver.")
        print(f"- Vui lÃ²ng kiá»ƒm tra xem báº¡n Ä‘Ã£ cÃ i Ä‘áº·t trÃ¬nh duyá»‡t Google Chrome chÆ°a.")
        print(f"- Lá»—i chi tiáº¿t: {e}")
        return None









# ===========================================================================================================================
# Ingesting News Functionality
# ===========================================================================================================================

SELECTORS = {
    "search_box": 'input[aria-label="TÃ¬m kiáº¿m chá»§ Ä‘á», vá»‹ trÃ­ vÃ  nguá»“n"]',
    "article_container": "article.IFHyqb",
    "link_and_title": "a.JtKRv",
    "source": "div.vr1PYe",
    "timestamp": "time.hvbAAd"
}

def _parse_page_source(soup: BeautifulSoup, seen_urls: set, keyword: str) -> list:
    """
    HÃ m phá»¥ trá»£: BÃ³c tÃ¡ch dá»¯ liá»‡u tá»« soup vÃ  tráº£ vá» cÃ¡c bÃ i viáº¿t Má»šI.
    """
    new_results = []
    articles = soup.select(SELECTORS["article_container"])

    for article in articles:
        link_tag = article.select_one(SELECTORS["link_and_title"])
        if not link_tag:
            continue

        relative_url = link_tag.get('href', '').lstrip('.')
        full_url = "https://news.google.com" + relative_url

        if full_url not in seen_urls:
            seen_urls.add(full_url)
            source_tag = article.select_one(SELECTORS["source"])
            time_tag = article.select_one(SELECTORS["timestamp"])

            new_results.append({
                'keyword': keyword,
                'title': link_tag.text.strip(),
                'source': source_tag.text.strip() if source_tag else "N/A",
                'timestamp': time_tag.text.strip() if time_tag else "N/A",
                'url': full_url
            })
    return new_results



from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
from newspaper import Article
def get_article_details(
    url: str,
    temp_driver
) -> str:
    """
    Sá»­ dá»¥ng newspaper3k Ä‘á»ƒ truy cáº­p má»™t URL vÃ  bÃ³c tÃ¡ch ná»™i dung chÃ­nh.
    """
    # TrÃ­ch xuáº¥t link gá»‘c
    def _get_original_url(
        url
    ):
        temp_driver.get(url)
        time.sleep(3) 
        real_url = temp_driver.current_url
        return real_url
    
    original_url = _get_original_url(url)
    try:
        # Táº£i vÃ  phÃ¢n tÃ­ch bÃ i bÃ¡o
        article = Article(original_url)
        article.download()
        article.parse()
        # Tráº£ vá» toÃ n bá»™ ná»™i dung text cá»§a bÃ i bÃ¡o
        return article.text
    except Exception as e:
        print(f"   -> Lá»—i khi bÃ³c tÃ¡ch url {url}: {e}")
        return "" # Tráº£ vá» chuá»—i rá»—ng náº¿u cÃ³ lá»—i




def get_news(keyword: str, driver: webdriver.Chrome, topk: int = 50) -> list | None:
    """
    HÃ m chÃ­nh: Äiá»u khiá»ƒn trÃ¬nh duyá»‡t, tÃ¬m kiáº¿m, cuá»™n trang vÃ  gá»i hÃ m phá»¥ trá»£ Ä‘á»ƒ bÃ³c tÃ¡ch.
    """
    if not driver:
        print("WebDriver khÃ´ng kháº£ dá»¥ng.")
        return None
    
    try:
        print(f"Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh láº¥y ÃT NHáº¤T {topk} tin cho tá»« khÃ³a: '{keyword}'")
        driver.get(MAIN_URL)
        
        search_box = driver.find_element(By.CSS_SELECTOR, SELECTORS["search_box"])
        search_box.click()
        search_box.send_keys(keyword + Keys.RETURN)
        time.sleep(3)
        print("-> TÃ¬m kiáº¿m thÃ nh cÃ´ng.")

        print("-> Báº¯t Ä‘áº§u cuá»™n trang linh hoáº¡t...")
        all_results = []
        seen_urls = set()
        patience = 3
        stalls = 0

        while True:
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            newly_found_articles = _parse_page_source(soup, seen_urls, keyword)

            if newly_found_articles:
                all_results.extend(newly_found_articles)
                print(f"   -> ÄÃ£ tÃ¬m tháº¥y {len(newly_found_articles)} tin má»›i. Tá»•ng cá»™ng: {len(all_results)}.")
            
            if len(all_results) >= topk:
                print(f"   -> ÄÃ£ Ä‘áº¡t hoáº·c vÆ°á»£t má»©c tá»‘i thiá»ƒu {topk} bÃ i viáº¿t. Dá»«ng cuá»™n.")
                break

            last_height = driver.execute_script("return document.body.scrollHeight")
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3.5)
            new_height = driver.execute_script("return document.body.scrollHeight")

            if new_height == last_height:
                stalls += 1
                if stalls >= patience:
                    print(f"   -> ÄÃ£ cuá»™n Ä‘áº¿n cuá»‘i trang. Dá»«ng láº¡i.")
                    break
            else:
                stalls = 0

        print(f"âœ… QuÃ¡ trÃ¬nh hoÃ n táº¥t. Thu Ä‘Æ°á»£c {len(all_results)} bÃ i viáº¿t.")
        return all_results

    except Exception as e:
        print(f"âŒ ÄÃ£ xáº£y ra lá»—i trong hÃ m get_news: {e}")
        return None
    








# ===========================================================================================================================
# LÆ°u dá»¯ liá»‡u
# ===========================================================================================================================
import os, json

def save(result, keyword):
    if result:
        # 1. Chuáº©n bá»‹ Ä‘Æ°á»ng dáº«n vÃ  tÃªn file Ä‘á»™ng
        output_dir = 'data'
        filename = f"news_{keyword.replace(' ', '_').lower()}.json"
        output_path = os.path.join(output_dir, filename)

        # 2. Äáº£m báº£o thÆ° má»¥c 'data' tá»“n táº¡i
        os.makedirs(output_dir, exist_ok=True)

        # 3. Má»Ÿ file vÃ  sá»­ dá»¥ng json.dump() Ä‘á»ƒ ghi dá»¯ liá»‡u
        # encoding='utf-8' lÃ  cáº§n thiáº¿t cho tiáº¿ng Viá»‡t
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(
                result,             # Dá»¯ liá»‡u cáº§n ghi (toÃ n bá»™ danh sÃ¡ch 'result')
                f,                  # Äá»‘i tÆ°á»£ng file Ä‘á»ƒ ghi vÃ o
                ensure_ascii=False, # Quan trá»ng: Äá»ƒ hiá»ƒn thá»‹ Ä‘Ãºng tiáº¿ng Viá»‡t cÃ³ dáº¥u
                indent=2            # Thá»¥t lá» 2 dáº¥u cÃ¡ch Ä‘á»ƒ file dá»… Ä‘á»c vÃ  "Ä‘áº¹p"
            )
        
        print(f"âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng file JSON vÃ o: '{output_path}'")
    else:
        print("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u.")

# ===========================================================================================================================
# Main Execution
# ===========================================================================================================================
def main():
    # INPUT
    keywords = ["Credit Suisse"] 

    # SELF-CONFIGURATION 
    driver = load_driver()
    temp_driver = load_driver()

    if not driver:
        print("KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver. Dá»«ng chÆ°Æ¡ng trÃ¬nh.")
        return
    if not temp_driver:
        print("KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver. Dá»«ng chÆ°Æ¡ng trÃ¬nh.")
        return
    
    # START EXECUTING TASK
    try:
        for keyword in keywords:
            result = get_news(keyword, driver)
            if result:
                print(f"\n--- Báº¯t Ä‘áº§u láº¥y ná»™i dung chi tiáº¿t cho {len(result)} bÃ i viáº¿t vá» '{keyword}' ---")

                for item in result:
                    print(f"-> Äang xá»­ lÃ½: {item['title'][:60]}...")
                    item['content'] = get_article_details(
                        item['url'],
                        temp_driver = temp_driver
                    )
                
                save(result, keyword)
            else:
                print(f"KhÃ´ng tÃ¬m tháº¥y bÃ i viáº¿t nÃ o cho tá»« khÃ³a '{keyword}'.")

    finally:
        if driver:
            driver.quit()
            print("\nÄÃ£ Ä‘Ã³ng WebDriver.")
        
    

main()